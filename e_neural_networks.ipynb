{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernanda-palacios/ai-code-notebooks/blob/main/e_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neural Networks for Digit Classification**\n",
        "\n",
        "A neural network with activation functions, dropout and batch normalization"
      ],
      "metadata": {
        "id": "QnlToVOV5cnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(1)\n",
        "\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST('data', train=False, download=True, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "id": "rUbaf0GHZory",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee861683-663f-4c57-b897-ea22b3967dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 28704439.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 109131255.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 37157639.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20797520.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train, valid, batch_size, train_iters, lr, device):\n",
        "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(valid, batch_size=batch_size, shuffle=True)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "    opt = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    model = model.to(device) # place model on the device specifed by the user\n",
        "\n",
        "    for i in range(train_iters):\n",
        "        train_loop = tqdm(train_loader, total=len(train_loader), position=0, leave=True) # loading bar for training loop\n",
        "        train_loop.set_description(f\"Training iteration [{i+1}/{train_iters}]\")\n",
        "        model = model.train()\n",
        "\n",
        "        for img_batch, labels in train_loop:\n",
        "            img_batch, labels = img_batch.to(device), labels.to(device) # placing input data and labels on the same device as model\n",
        "            num_batches = img_batch.shape[0]\n",
        "            img_batch = img_batch.view(num_batches, -1) # reshaping/flattening input data\n",
        "\n",
        "            opt.zero_grad()\n",
        "            predictions = model(img_batch)\n",
        "            loss = crit(predictions, labels)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            train_loop.set_postfix(loss = loss.item()) # gives the loss to the loading bar for display\n",
        "\n",
        "        num_correct = 0\n",
        "        for img_batch, labels in test_loader:\n",
        "            num_batches = img_batch.shape[0]\n",
        "            img_batch, labels = img_batch.to(device).view(num_batches, -1), labels.to(device)\n",
        "            with torch.no_grad(): # tells torch not to accumulate gradients, which we do not need while testing since we are not updating any weights or biases\n",
        "                predictions = model(img_batch)\n",
        "                predicted_probabilities = F.softmax(predictions, dim=-1) # turning output values (usually referred to as logits) into probabilities\n",
        "                highest_probs = predicted_probabilities.argmax(dim=-1) # taking the index values of highest probabilities\n",
        "                num_correct = num_correct + (highest_probs == labels).sum().item()\n",
        "        print(f\"Testing accuracy: {num_correct/len(valid)}\")"
      ],
      "metadata": {
        "id": "ti7Ph6-udFau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTClassifierWithDropoutAndBatchNorm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifierWithDropoutAndBatchNorm, self).__init__()\n",
        "        self.layer1 = nn.Linear(28 * 28, 50)\n",
        "        self.layer2 = nn.Linear(50, 20)\n",
        "        self.layer3 = nn.Linear(20, 10)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        self.dropout3 = nn.Dropout(0.4)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(50)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(20)\n",
        "\n",
        "    def forward(self, img):\n",
        "        flattened = img.view(-1, 28 * 28)\n",
        "        activation1 = F.relu(self.batch_norm1(self.layer1(self.dropout1(flattened))))\n",
        "        activation2 = F.relu(self.batch_norm2(self.layer2(self.dropout2(activation1))))\n",
        "        output = self.layer3(self.dropout3(activation2))\n",
        "        return output"
      ],
      "metadata": {
        "id": "Q2NERdptUopX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MNISTClassifierWithDropoutAndBatchNorm().to(\"cuda\")\n",
        "\n",
        "def num_trainable_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Number of trainable parameters: \", num_trainable_params(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRDsm7jCH-4S",
        "outputId": "46757ee6-e3b1-414f-aa47-280a7608871a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters:  40620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    model=model,\n",
        "    train=mnist_train,\n",
        "    valid=mnist_test,\n",
        "    batch_size=128,\n",
        "    train_iters=9,\n",
        "    lr=0.01,\n",
        "    device=\"cuda\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SPd3hVDQgX3",
        "outputId": "fc55ee9d-5e05-4c0e-89bd-602b0b97d9b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [1/9]: 100%|██████████| 469/469 [00:09<00:00, 47.44it/s, loss=1.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.5473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [2/9]: 100%|██████████| 469/469 [00:09<00:00, 49.38it/s, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.6295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [3/9]: 100%|██████████| 469/469 [00:09<00:00, 48.15it/s, loss=1.11]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.6718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [4/9]: 100%|██████████| 469/469 [00:08<00:00, 52.14it/s, loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.6978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [5/9]: 100%|██████████| 469/469 [00:08<00:00, 53.77it/s, loss=0.847]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.712\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [6/9]: 100%|██████████| 469/469 [00:09<00:00, 51.72it/s, loss=0.779]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.7282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [7/9]: 100%|██████████| 469/469 [00:09<00:00, 50.53it/s, loss=0.979]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [8/9]: 100%|██████████| 469/469 [00:09<00:00, 50.21it/s, loss=0.683]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.7476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training iteration [9/9]: 100%|██████████| 469/469 [00:09<00:00, 51.37it/s, loss=0.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: 0.7541\n"
          ]
        }
      ]
    }
  ]
}